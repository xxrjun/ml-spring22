{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TextGeneration-109403019.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRBvwrOM15OY"
      },
      "source": [
        "<img src=\"https://i.imgur.com/12tfKrD.png\" alt=\"Alin\">\n",
        "</img>\n",
        "\n",
        "\n",
        "# Demo RNN -- 張愛玲散文集AI二次創作\n",
        "\n",
        "資料集: 張愛玲繁體中文小說 《傳奇》\n",
        "\n",
        "爬蟲來源: [crawl_book](https://colab.research.google.com/drive/1f_HvQEvgkJPFc473TlA-I_3EmkThA2SR?usp=sharing)\n",
        "\n",
        "程式碼參考: [Tensorflow](https://www.tensorflow.org/tutorials/text/text_generation)\n",
        "\n",
        "本次資料集，著作權乃是張愛玲女士所擁有。**請勿將本次資料集散播、更改、用於非商業用途**。\n",
        "\n",
        "> **資料集說明**\n",
        "\n",
        "今年是張愛玲女士101年誕辰。張愛玲出生名門，曾就讀於香港大學和聖約翰大學，受過良好的中西教育。上海淪陷時期，陸續發表《沉香屑·第一爐香》、《傾城之戀》、《心經》、《金鎖記》等中、短篇小說，震動上海文壇。\n",
        "\n",
        "這次訓練取張愛玲散文集《傳奇》作為訓練，《傳奇》收留五篇散文: 「留情」、「鴻鸞禧」、「紅玫瑰與白玫瑰」、「等」、「桂花蒸阿小悲秋」。其中以「紅玫瑰與白玫瑰」最為膾炙人口。\n",
        "\n",
        "> **訓練步驟**\n",
        "\n",
        "深度學習在訓練模型上有以下幾個重要的步驟:\n",
        "1. 讀入相關封包\n",
        "2. 取得資料集 \n",
        "3. 資料前處理\n",
        "4. 建立模型\n",
        "5. 制定訓練計畫\n",
        "6. 評估模型\n",
        "7. 做預測\n",
        "\n",
        "> **本次模型介紹 RNN**\n",
        "\n",
        "![](https://i.imgur.com/FaY50C8.png)\n",
        "\n",
        "\n",
        "我們來看看維度，很多人會搞不懂RNN的維度:\n",
        "\n",
        "一個Seq通過RNN後的維度\n",
        "\n",
        "* Input: (Seq,${originDim}$)\n",
        "* RNN Neuron: 2048\n",
        "* Output: (Seq,2048) if (return_sequence == True) else (1,2048)\n",
        "![](https://i.imgur.com/9SVl6JR.png)\n",
        "\n",
        "![](https://i.imgur.com/z4ElFIr.png)\n",
        "\n",
        "> **把生成問題變成分類問題**\n",
        "\n",
        "![](https://i.imgur.com/TBHKuf6.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoKPksUD96Mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c24700c-4c0d-4b65-9a90-cadd04f064fa"
      },
      "source": [
        "# ****************************************\n",
        "# **請勿將本次資料集散播、用於非學術用途**\n",
        "# ****************************************\n",
        "\n",
        "# 執行即代表同意將會合法、合理使用資料集\n",
        "# 太多人同時存取可能會報cannot retrieve file error\n",
        "# 點擊you may still be able to access 下面那個連結再自行上傳檔案即可\n",
        "\n",
        "# !gdown --id 1gMpt0CdlPjr1cR3HwDqumeKaucrSYhhe --output \"./Eileen_Legendary.txt\"\n",
        "\n",
        "# !wget -O Eileen_Legendary.txt \"http://140.115.82.54/NN/Recurrent/Eileen_Legendary.txt\"\n",
        "\n",
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1uNgsjCp11BjIHYBwyL48gc2XL-boO5Kz' -O Shakespeare_Twelfth_Nigh.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-12 23:58:37--  https://drive.google.com/uc?export=download&id=1uNgsjCp11BjIHYBwyL48gc2XL-boO5Kz\n",
            "Resolving drive.google.com (drive.google.com)... 172.253.115.138, 172.253.115.100, 172.253.115.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|172.253.115.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-14-38-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/72bq857hd6g69u10od9voc57g21fv9ut/1652399850000/14055454935798647983/*/1uNgsjCp11BjIHYBwyL48gc2XL-boO5Kz?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-05-12 23:58:38--  https://doc-14-38-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/72bq857hd6g69u10od9voc57g21fv9ut/1652399850000/14055454935798647983/*/1uNgsjCp11BjIHYBwyL48gc2XL-boO5Kz?e=download\n",
            "Resolving doc-14-38-docs.googleusercontent.com (doc-14-38-docs.googleusercontent.com)... 142.250.65.65, 2607:f8b0:4004:832::2001\n",
            "Connecting to doc-14-38-docs.googleusercontent.com (doc-14-38-docs.googleusercontent.com)|142.250.65.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 122797 (120K) [text/plain]\n",
            "Saving to: ‘Shakespeare_Twelfth_Nigh.txt’\n",
            "\n",
            "Shakespeare_Twelfth 100%[===================>] 119.92K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-05-12 23:58:38 (107 MB/s) - ‘Shakespeare_Twelfth_Nigh.txt’ saved [122797/122797]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aEUrr67TzFb"
      },
      "source": [
        "## 1. 讀入Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPCmAo0Q_G3i"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y550TvUGT9xv"
      },
      "source": [
        "## 2. 取得資料集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mbvzh_9_Tz8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52eb0a7b-d761-4e30-e5db-ec931d43d821"
      },
      "source": [
        "# 作業之一就是試試看其他本小說\n",
        "\n",
        "book = \"\"\n",
        "with open(\"./Shakespeare_Twelfth_Nigh.txt\",\"r\",encoding=\"utf8\") as file:\n",
        "  for line in file:\n",
        "    book += line\n",
        "\n",
        "book_length = len(book)\n",
        "unique_words = set(book)\n",
        "print(f\"莎士比亞《第十二夜》共有 {book_length} 字詞\")\n",
        "print(f\"包含了 {len(unique_words)} 個獨一無二的字 (含標點符號)\\n\")\n",
        "print(book[0:500])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "莎士比亞《第十二夜》共有 42369 字詞\n",
            "包含了 2003 個獨一無二的字 (含標點符號)\n",
            "\n",
            "\n",
            "《二○一五年四月三日版》\n",
            "《好讀書櫃》經典版\n",
            "劇中人物\n",
            "奧西諾 伊利里亞公爵\n",
            "西巴斯辛 薇奧拉之兄\n",
            "安東尼奧 船長，西巴斯辛之友\n",
            "另一船長 薇奧拉之友\n",
            "凡倫丁，丘里奧 公爵侍臣\n",
            "托比．培爾契爵士 奧麗維亞的叔父\n",
            "安德魯．艾古契克爵士\n",
            "馬伏里奧 奧麗維亞的管家\n",
            "費邊\n",
            "費斯特 小丑，奧麗維亞之僕\n",
            "奧麗維亞 富有的伯爵小姐\n",
            "薇奧拉 熱戀公爵者\n",
            "瑪利亞 奧麗維亞的侍女\n",
            "群臣、牧師、水手、警吏、樂工及其他侍從等\n",
            "地點 伊利里亞某城及其附近海濱\n",
            "\n",
            "\n",
            "第一場 公爵府中一室\n",
            "──公爵、丘里奧、眾臣同上；樂工隨侍。\n",
            "公爵 假如音樂是愛情的食糧，那麼奏下去吧；盡量地奏下去，好讓愛情因過飽噎塞而死。又奏起這個調子來了！它有一種漸漸消沉下去的節奏。啊！它經過我的耳畔，就像微風吹拂一叢紫羅蘭，發出輕柔的聲音，一面把花香偷走，一面又把花香分送。夠了！別再奏下去了！它現在已經不像原來那樣甜蜜了。愛情的精靈呀！你是多麼敏感而活潑；雖然你有海一樣的容量，可是無論怎樣高貴超越的事物，一進了你的範圍，便會在頃刻間失去了它的價值。愛情是這樣充滿了意象，在一切事物中是最富於幻想的。\n",
            "丘里奧 殿下，您要不要去打獵？\n",
            "公爵 什麼\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anv0UglDUQk2"
      },
      "source": [
        "## 3. 資料前處理\n",
        "\n",
        "文字前處理有一堆方法、作法:\n",
        "* 切字\n",
        "* 還原\n",
        "* 清除特殊字符\n",
        "* 清除不常見字符 (StopWord)\n",
        "\n",
        "\n",
        "我這裡僅使用去除不常見的字(StopWord)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQDQ8hxBEa6d"
      },
      "source": [
        "# 計算字數統計\n",
        "words_count = {}\n",
        "for w in book:\n",
        "  if w in words_count:\n",
        "    words_count[w] += 1\n",
        "  else:\n",
        "    words_count[w] = 1\n",
        "\n",
        "words_count = sorted(words_count.items(),key=lambda x:x[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT90O679Fe0T",
        "outputId": "df9f8b30-a3d7-4267-e4a7-b5cdf539bbe6"
      },
      "source": [
        "stop_word = 8\n",
        "unique_words = [w_tup[0] for w_tup in words_count if w_tup[1]>stop_word]\n",
        "print(f\"去除次數小於{stop_word}的文字剩餘 : {len(unique_words)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "去除次數小於8的文字剩餘 : 571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_uP5gOVIy2K",
        "outputId": "50f934e3-97fd-4123-a1d8-06e760fd65eb"
      },
      "source": [
        "print(f\"原本莎士比亞《第十二夜》共有 {book_length} 字詞\")\n",
        "print(f\"去除不常出現的文字後\")\n",
        "book = [w for w in book if w in unique_words]\n",
        "print(f\"剩餘{len(book)}個字\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原本莎士比亞《第十二夜》共有 42369 字詞\n",
            "去除不常出現的文字後\n",
            "剩餘38475個字\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LP0BwFDAmcS",
        "outputId": "2f5bda7e-1443-4c7b-c656-f31a91f4f076"
      },
      "source": [
        "# 文字轉數字(index)\n",
        "word_2_index = {word:index for index,word in enumerate(unique_words)}\n",
        "index_2_word = {word_2_index[word]:word for word in word_2_index}\n",
        "\n",
        "book_2_index = [word_2_index[w] for w in book]\n",
        "\n",
        "print(\"原始文字 : \")\n",
        "print(book[:40])\n",
        "print(\"-\"*40)\n",
        "print(\"轉成index : \")\n",
        "print({word_2_index[w] for w in book[:40]})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原始文字 : \n",
            "['\\n', '《', '二', '一', '年', '四', '三', '》', '\\n', '《', '好', '讀', '書', '》', '經', '\\n', '中', '人', '物', '\\n', '奧', '西', '諾', ' ', '伊', '利', '里', '亞', '公', '爵', '\\n', '西', '巴', '斯', '辛', ' ', '薇', '奧', '拉', '之']\n",
            "----------------------------------------\n",
            "轉成index : \n",
            "{0, 1, 2, 515, 517, 518, 137, 138, 402, 530, 542, 546, 426, 555, 560, 433, 562, 565, 566, 437, 195, 196, 451, 85, 469, 344, 484, 488, 495, 496, 242}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-KDv4kqgxLH"
      },
      "source": [
        "def ind2word_seq(seq):\n",
        "  return [index_2_word[i] for i in seq]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aDyjJymDmVv",
        "outputId": "524580f3-78d2-4c02-93f4-c602522c5877"
      },
      "source": [
        "# 設定輸入模型長度\n",
        "seq_len = 20\n",
        "characters = tf.data.Dataset.from_tensor_slices(book_2_index)\n",
        "# characters = characters.map(lambda w:word_2_index[w.item()])\n",
        "\n",
        "sequences = characters.batch(seq_len+1,drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(2):\n",
        "  print(seq.shape)\n",
        "  print(seq)\n",
        "  print([index_2_word[i] for i in seq.numpy()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21,)\n",
            "tf.Tensor(\n",
            "[566   0 137 562 402 138 344   1 566   0 542 242   2   1 484 566 433 555\n",
            "  85 566 560], shape=(21,), dtype=int32)\n",
            "['\\n', '《', '二', '一', '年', '四', '三', '》', '\\n', '《', '好', '讀', '書', '》', '經', '\\n', '中', '人', '物', '\\n', '奧']\n",
            "(21,)\n",
            "tf.Tensor(\n",
            "[496 195 565 196 495 530 546 488 515 566 496 451 469 426 565 517 560 518\n",
            " 437 197 566], shape=(21,), dtype=int32)\n",
            "['西', '諾', ' ', '伊', '利', '里', '亞', '公', '爵', '\\n', '西', '巴', '斯', '辛', ' ', '薇', '奧', '拉', '之', '兄', '\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-dxqFkd7RU1"
      },
      "source": [
        "![](https://i.imgur.com/YMVMFEJ.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhFC16MdLONw",
        "outputId": "685a1d7a-67e5-44cd-8a17-59a4ceb960d7"
      },
      "source": [
        "# 做input、target切割\n",
        "def split_input_target(seq):\n",
        "  input_txt = seq[:-1]\n",
        "  target_txt = seq[1:]\n",
        "  return input_txt,target_txt\n",
        "\n",
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-O91DUM_uYV"
      },
      "source": [
        "![](https://i.imgur.com/YoHWLkf.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnJ4Bdj2gZ1V",
        "outputId": "e8ec89ae-7b63-47d5-df65-8fc14ef03c82"
      },
      "source": [
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  print(\"Input :\", ind2word_seq(input_example.numpy()))\n",
        "  print(\"Target:\", ind2word_seq(target_exaple.numpy()))\n",
        "  print(\"-\"*50)\n",
        "  print(\"Input :\", input_example.numpy())\n",
        "  print(\"Target:\", target_exaple.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : ['\\n', '《', '二', '一', '年', '四', '三', '》', '\\n', '《', '好', '讀', '書', '》', '經', '\\n', '中', '人', '物', '\\n']\n",
            "Target: ['《', '二', '一', '年', '四', '三', '》', '\\n', '《', '好', '讀', '書', '》', '經', '\\n', '中', '人', '物', '\\n', '奧']\n",
            "--------------------------------------------------\n",
            "Input : [566   0 137 562 402 138 344   1 566   0 542 242   2   1 484 566 433 555\n",
            "  85 566]\n",
            "Target: [  0 137 562 402 138 344   1 566   0 542 242   2   1 484 566 433 555  85\n",
            " 566 560]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNivSh2Igr2-",
        "outputId": "ae8087e1-4659-4cca-acd8-5f44389dead5"
      },
      "source": [
        "# 建立資料集\n",
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True))\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(64, 20), dtype=tf.int32, name=None), TensorSpec(shape=(64, 20), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcDWKSbYUWWB"
      },
      "source": [
        "## 4. 建立模型\n",
        "\n",
        "![](https://i.imgur.com/TBHKuf6.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkRcSZAHnxlk",
        "outputId": "92921a40-91f8-4ea4-bffc-104df43ec7b7"
      },
      "source": [
        "# 超參數\n",
        "EMBEDDING_DIM = 512\n",
        "\n",
        "# 使用 keras 建立一個非常簡單的 LSTM 模型\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.Embedding(\n",
        "    input_dim=len(unique_words), \n",
        "    output_dim=EMBEDDING_DIM\n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=4096, \n",
        "    return_sequences=True, \n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=2048, \n",
        "    return_sequences=True,\n",
        "))\n",
        "  \n",
        "model.add(\n",
        "  tf.keras.layers.Dense(\n",
        "      len(unique_words),activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 512)         292352    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, None, 4096)        75513856  \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, None, 2048)        50339840  \n",
            "                                                                 \n",
            " dense (Dense)               (None, None, 571)         1169979   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 127,316,027\n",
            "Trainable params: 127,316,027\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKiszF5doFGz",
        "outputId": "e83d30e7-7088-4750-9947-815596d7f458"
      },
      "source": [
        "# 查看模型的輸入、輸出 shape\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  predict_example = model(input_example)\n",
        "  print(f\"Model input shape : {input_example.shape}\")\n",
        "  print(f\"Model output shape : {predict_example.shape}\")\n",
        "  print(f\"Model target shape : {target_exaple.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model input shape : (64, 20)\n",
            "Model output shape : (64, 20, 571)\n",
            "Model target shape : (64, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsN6Zz4NReV4",
        "outputId": "9fbb4d42-50a0-4a94-efb8-dce601f6f315"
      },
      "source": [
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入尚未訓練的model後獲得：\")\n",
        "print()\n",
        "\n",
        "predict_words = tf.math.argmax(predict_example[0],-1)\n",
        "[print(index_2_word[ind],end=\"\") for ind in predict_words.numpy()]\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原本的中文字序列：\n",
            "你的父？\n",
            "薇奧拉 我是薩人。西巴斯辛是我\n",
            "----------------------------------------\n",
            "輸入尚未訓練的model後獲得：\n",
            "\n",
            "呢味味容容差教教教無行行也也也半伙艾艾死\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peEbrfDrUfuz"
      },
      "source": [
        "## 5. 制定訓練計畫並訓練\n",
        "\n",
        "* [sparse_categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparse_categorical_crossentropy) V.S. [categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_crossentropy)\n",
        "\n",
        "```python=\n",
        "# categorical_crossentropy\n",
        "y_true = [[0, 1, 0], [0, 0, 1]]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "assert loss.shape == (2,)\n",
        "\n",
        "# sparse_categorical_crossentropy\n",
        "y_true = [1, 2]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "assert loss.shape == (2,)\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unPfQAQBonFj"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IW5xiiMpJhJ",
        "outputId": "cc17cfce-2a75-478d-9e9a-506c59b05fe1"
      },
      "source": [
        "EPOCHS = 50\n",
        "history = model.fit(\n",
        "    dataset, # 前面使用 tf.data 建構的資料集\n",
        "    epochs=EPOCHS,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "28/28 [==============================] - 11s 297ms/step - loss: 5.8698\n",
            "Epoch 2/50\n",
            "28/28 [==============================] - 8s 299ms/step - loss: 5.3798\n",
            "Epoch 3/50\n",
            "28/28 [==============================] - 9s 304ms/step - loss: 5.0553\n",
            "Epoch 4/50\n",
            "28/28 [==============================] - 9s 305ms/step - loss: 4.7266\n",
            "Epoch 5/50\n",
            "28/28 [==============================] - 9s 312ms/step - loss: 4.4176\n",
            "Epoch 6/50\n",
            "28/28 [==============================] - 9s 312ms/step - loss: 4.1129\n",
            "Epoch 7/50\n",
            "28/28 [==============================] - 9s 313ms/step - loss: 3.8679\n",
            "Epoch 8/50\n",
            "28/28 [==============================] - 9s 316ms/step - loss: 3.6642\n",
            "Epoch 9/50\n",
            "28/28 [==============================] - 9s 320ms/step - loss: 3.4629\n",
            "Epoch 10/50\n",
            "28/28 [==============================] - 9s 323ms/step - loss: 3.2420\n",
            "Epoch 11/50\n",
            "28/28 [==============================] - 9s 325ms/step - loss: 2.9574\n",
            "Epoch 12/50\n",
            "28/28 [==============================] - 9s 329ms/step - loss: 2.5964\n",
            "Epoch 13/50\n",
            "28/28 [==============================] - 9s 331ms/step - loss: 2.1617\n",
            "Epoch 14/50\n",
            "28/28 [==============================] - 9s 332ms/step - loss: 1.6563\n",
            "Epoch 15/50\n",
            "28/28 [==============================] - 9s 334ms/step - loss: 1.1615\n",
            "Epoch 16/50\n",
            "28/28 [==============================] - 9s 336ms/step - loss: 0.7893\n",
            "Epoch 17/50\n",
            "28/28 [==============================] - 10s 338ms/step - loss: 0.5457\n",
            "Epoch 18/50\n",
            "28/28 [==============================] - 10s 340ms/step - loss: 0.4165\n",
            "Epoch 19/50\n",
            "28/28 [==============================] - 9s 335ms/step - loss: 0.3485\n",
            "Epoch 20/50\n",
            "28/28 [==============================] - 9s 335ms/step - loss: 0.3062\n",
            "Epoch 21/50\n",
            "28/28 [==============================] - 9s 336ms/step - loss: 0.2754\n",
            "Epoch 22/50\n",
            "28/28 [==============================] - 9s 337ms/step - loss: 0.2552\n",
            "Epoch 23/50\n",
            "28/28 [==============================] - 10s 338ms/step - loss: 0.2417\n",
            "Epoch 24/50\n",
            "28/28 [==============================] - 10s 339ms/step - loss: 0.2284\n",
            "Epoch 25/50\n",
            "28/28 [==============================] - 10s 340ms/step - loss: 0.2178\n",
            "Epoch 26/50\n",
            "28/28 [==============================] - 10s 341ms/step - loss: 0.2107\n",
            "Epoch 27/50\n",
            "28/28 [==============================] - 10s 342ms/step - loss: 0.2019\n",
            "Epoch 28/50\n",
            "28/28 [==============================] - 10s 343ms/step - loss: 0.1980\n",
            "Epoch 29/50\n",
            "28/28 [==============================] - 10s 344ms/step - loss: 0.1925\n",
            "Epoch 30/50\n",
            "28/28 [==============================] - 10s 344ms/step - loss: 0.1877\n",
            "Epoch 31/50\n",
            "28/28 [==============================] - 10s 345ms/step - loss: 0.1847\n",
            "Epoch 32/50\n",
            "28/28 [==============================] - 10s 346ms/step - loss: 0.1805\n",
            "Epoch 33/50\n",
            "28/28 [==============================] - 10s 347ms/step - loss: 0.1776\n",
            "Epoch 34/50\n",
            "28/28 [==============================] - 10s 346ms/step - loss: 0.1746\n",
            "Epoch 35/50\n",
            "28/28 [==============================] - 10s 346ms/step - loss: 0.1733\n",
            "Epoch 36/50\n",
            "28/28 [==============================] - 10s 346ms/step - loss: 0.1716\n",
            "Epoch 37/50\n",
            "28/28 [==============================] - 10s 347ms/step - loss: 0.1695\n",
            "Epoch 38/50\n",
            "28/28 [==============================] - 10s 347ms/step - loss: 0.1678\n",
            "Epoch 39/50\n",
            "28/28 [==============================] - 10s 348ms/step - loss: 0.1658\n",
            "Epoch 40/50\n",
            "28/28 [==============================] - 10s 348ms/step - loss: 0.1643\n",
            "Epoch 41/50\n",
            "28/28 [==============================] - 10s 349ms/step - loss: 0.1640\n",
            "Epoch 42/50\n",
            "28/28 [==============================] - 10s 349ms/step - loss: 0.1631\n",
            "Epoch 43/50\n",
            "28/28 [==============================] - 10s 349ms/step - loss: 0.1614\n",
            "Epoch 44/50\n",
            "28/28 [==============================] - 10s 349ms/step - loss: 0.1592\n",
            "Epoch 45/50\n",
            "28/28 [==============================] - 10s 349ms/step - loss: 0.1589\n",
            "Epoch 46/50\n",
            "28/28 [==============================] - 10s 350ms/step - loss: 0.1599\n",
            "Epoch 47/50\n",
            "28/28 [==============================] - 10s 350ms/step - loss: 0.1580\n",
            "Epoch 48/50\n",
            "28/28 [==============================] - 10s 351ms/step - loss: 0.1573\n",
            "Epoch 49/50\n",
            "28/28 [==============================] - 10s 351ms/step - loss: 0.1567\n",
            "Epoch 50/50\n",
            "28/28 [==============================] - 10s 351ms/step - loss: 0.1560\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-DD-OibUj64"
      },
      "source": [
        "## 6. 衡量模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxbK80fXpOWD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "1f2ee10d-71c3-40d7-eaea-ba357b30fa84"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhcZZn38e9d1fuWztLZOitkIQtZoIlAEJFgiBCIIAqDoCBjnBkd4gyK4quD47jM4usKr0NYFBVRBggCIrJFlkECnYWEbCwhIXt3yNKdpff7/aNOJ52QhO6kT5+uU7/PddVVdU6dOs99msqvHp469Rxzd0REJH4SURcgIiLhUMCLiMSUAl5EJKYU8CIiMaWAFxGJKQW8iEhMKeBFADP7pZl9p53brjWz8453PyJhU8CLiMSUAl5EJKYU8JI2gqGRr5jZUjPbY2Z3mlk/M/uTmdWa2VNm1rPN9heb2XIz22lmfzGzMW2em2xmi4LX/R7IO6StmWa2JHjti2Y24Rhr/pyZvWlm283sYTMbGKw3M/uRmVWZWY2ZLTOz8cFzF5jZiqC2jWb25WP6g0nGU8BLuvk48BFgFHAR8Cfg60AZqffz9QBmNgq4F/hS8NxjwCNmlmNmOcBDwK+BXsD/BPsleO1k4C7g80Bv4DbgYTPL7UihZnYu8H3gk8AAYB3wu+Dp6cDZwXH0CLZ5N3juTuDz7l4MjAee6Ui7Iq0U8JJufubuW919I/A8sMDdF7t7HTAPmBxsdznwR3d/0t0bgR8A+cCZwOlANvBjd2909/uBV9q0MRu4zd0XuHuzu98N1Aev64hPAXe5+yJ3rwduAs4ws2FAI1AMnASYu690983B6xqBsWZW4u473H1RB9sVARTwkn62tnm87zDLRcHjgaR6zAC4ewuwHigPntvoB8+0t67N46HADcHwzE4z2wkMDl7XEYfWsJtUL73c3Z8BbgFuBarMbK6ZlQSbfhy4AFhnZs+a2RkdbFcEUMBLfG0iFdRAasybVEhvBDYD5cG6VkPaPF4PfNfdS9vcCtz93uOsoZDUkM9GAHf/qbufCowlNVTzlWD9K+4+C+hLaijpvg62KwIo4CW+7gMuNLNpZpYN3EBqmOVF4K9AE3C9mWWb2aXAlDavvR34OzP7QPBlaKGZXWhmxR2s4V7gWjObFIzff4/UkNJaMzst2H82sAeoA1qC7wg+ZWY9gqGlGqDlOP4OksEU8BJL7r4auAr4GbCN1BeyF7l7g7s3AJcC1wDbSY3XP9jmtZXA50gNoewA3gy27WgNTwHfBB4g9X8NJwJXBE+XkPog2UFqGOdd4L+C564G1ppZDfB3pMbyRTrMdMEPEZF4Ug9eRCSmFPAiIjGlgBcRiSkFvIhITGVFXUBbffr08WHDhkVdhohI2li4cOE2dy873HPdKuCHDRtGZWVl1GWIiKQNM1t3pOc0RCMiElOhBryZlZrZ/Wa2ysxWak4NEZGuE/YQzU+Ax939smCK1oKQ2xMRkUBoAW9mPUjNd30NQPDz8Iaw2hMRkYOFOUQzHKgGfmFmi83sjmA2vYOY2WwzqzSzyurq6hDLERHJLGEGfBZwCvBzd59Masa8rx26kbvPdfcKd68oKzvsmT4iInIMwgz4DcAGd18QLN9PKvBFRKQLhBbw7r4FWG9mo4NV04AVnd1OXWMztz+3hhff3NbZuxYRSWthn0Xzj8A9wRk0a4BrO7uBrIQx9/k1TB5cypkj+nT27kVE0laoAe/uS4CKMNvISib42KSB/PLFtWzf00CvwpwwmxMRSRux+CXrpacMorHZeXTppqhLERHpNmIR8GMGlDBmQAkPLtoYdSkiIt1GLAIe4OOnlLNk/U7eqt4ddSkiIt1CbAL+4okDSRjMUy9eRASIUcD3LcnjgyPLmLd4Iy0tupC4iEhsAh7g0lPK2bhzHwve3h51KSIikYtVwE8f25+i3CzmLd4QdSkiIpGLVcDn5yT56Pj+PLZsC/samqMuR0QkUrEKeEidE7+7voknVmyJuhQRkUjFLuA/MLwX5aX5OideRDJe7AI+kTAumVzO829UU1VbF3U5IiKRiV3AA1xySjktDg8v0dQFIpK5YhnwJ5YVMXFwKQ9omEZEMlgsAx5SUxes3FzDik01UZciIhKJ2Ab8zAkDyU4aDy7SOfEikpliG/C9CnOYPrY/v3tlPdt210ddjohIl4ttwAP88/RR7Gts5idPvRF1KSIiXS7WAX9iWRFXThnCb19+hzerNI2wiGSWWAc8wJzzRpKfneQ/Hl8VdSkiIl0q9gHfpyiXvz/nRJ5csZWX1rwbdTkiIl0m9gEPcN1ZwxnQI4/vPbZSc8WLSMbIiIDPy07y5emjWbphF4/owtwikiEyIuABLplcztgBJfzn46upa9RUwiISfxkT8ImE8X8uHMPGnfu4+8W1UZcjIhK6jAl4gKkj+vDh0WXcMv9NduxpiLocEZFQhRrwZrbWzJaZ2RIzqwyzrfa66YIx7Klv4qfP6MdPIhJvXdGD/7C7T3L3ii5o632N6lfM5acN5td/XcfabXuiLkdEJDQZNUTT6p/OG0V2MsF/PbE66lJEREITdsA78ISZLTSz2YfbwMxmm1mlmVVWV1eHXE5K35I8Pnf2Cfxx6WYWv7OjS9oUEelqYQf8We5+CvBR4AtmdvahG7j7XHevcPeKsrKykMs5YPbZJ9CnKIfv/2kV7vrxk4jET6gB7+4bg/sqYB4wJcz2OqIoN4s500by8tvbeWZVVdTliIh0utAC3swKzay49TEwHXgtrPaOxRVThjC8TyH//qdVNDW3RF2OiEinCrMH3w94wcxeBV4G/ujuj4fYXodlJxN8dcZo3qjazf0LdeUnEYmXrLB27O5rgIlh7b+znD+uP6cMKeWHT77OxZMGUpAT2p9ERKRLZeRpkm2ZGV+/YAxVtfXc+fzbUZcjItJpMj7gASqG9WL62H7c9twaXb9VRGJDAR+4ccZJ7Gts5mdPawoDEYkHBXxgRN8irjhtMPcseIe3qnX9VhFJfwr4Nr503ijyspN859EVUZciInLcFPBtlBXncv20EcxfXc18/fhJRNKcAv4Q15w5nBP6FPJvj66goUk/fhKR9KWAP0ROVoJvzhzLmm17dOUnEUlrCvjD+PBJffnw6DJ++vQbVNfqtEkRSU8K+CP4xsyx7Gts5gd/1pzxIpKeFPBHcGJZEddOHcZ9C9ezbMOuqMsREekwBfxR/OO0kfQuzOFbjyzXnPEiknYU8EdRkpfNjeefxMJ1O3j41U1RlyMi0iEK+Pdx2amDOLm8B99/bBV7G5qiLkdEpN0U8O8jkTC+dfFYttTUcev8N6MuR0Sk3RTw7XDq0F5cMrmc2597m3Xv7om6HBGRdlHAt9NNHz2J7KTxb5qnRkTShAK+nfqW5HH9tJE8tbKK+as1T42IdH8K+A64dmpqnppvP7KC+qbmqMsRETkqBXwH5GQl+JeLxvL2tj3c9cLaqMsRETkqBXwHnTO6L+eN6cfPnnmDrTV1UZcjInJECvhj8C8zx9LU4nz/sZVRlyIickQK+GMwpHcBnz/7BB5asolX1m6PuhwRkcNSwB+jfzhnBAN75HHzH5bT3KJ5akSk+1HAH6P8nCRfv3AMKzbX8JuX1kVdjojIeyjgj8OFJw/g7FFlfP9PK3l9a23U5YiIHCT0gDezpJktNrNHw26rq5kZP/jEBIpys/jibxdR16hz40Wk++iKHvwcILanm/QtzuOHn5zE61t3axoDEelWQg14MxsEXAjcEWY7UTt7VBmf/9AJ3LPgHR5btjnqckREgPB78D8GbgRajrSBmc02s0ozq6yurg65nPB8efpoJg4u5asPLGX99r1RlyMiEl7Am9lMoMrdFx5tO3ef6+4V7l5RVlYWVjmhy04m+NkVk8Hh+t8tprH5iJ9pIiJdIswe/FTgYjNbC/wOONfMfhNie5Eb0ruA7116Movf2cmPnnw96nJEJMOFFvDufpO7D3L3YcAVwDPuflVY7XUXF00cyBWnDebnz77F82+k75CTiKQ/nQcfgpsvGseIsiKuv3cxb2/TFaBEJBpdEvDu/hd3n9kVbXUH+TlJbv90BWbGNb94mW2766MuSUQykHrwIRnWp5A7PlPB1po6rru7kr0NTVGXJCIZRgEfolOG9OSnV0xm2YadXH/vYpp0Zo2IdCEFfMimj+vPty4ex1Mrq/jWI8tx18yTItI1sqIuIBN8+oxhbNy5j9ueXcPA0nz+4ZwRUZckIhlAAd9Fvnr+SWzaWcd/Pr6agT3y+djk8qhLEpGYU8B3kUQiNfNkVU0dX7n/VcqKc5k6ok/UZYlIjGkMvgvlZiWZ++kKhvcp5PO/XsjyTbuiLklEYkwB38V65Gdz92enUJyXxTW/eEUTk4lIaBTwERjQI5+7PzuF+sZmPvOLl9mxpyHqkkQkhhTwERnVr5jbP13Bhh37+NtfVepqUCLS6RTwEfrACb358eWTWPTODv7x3sU0t+gceRHpPAr4iF1w8gBunjmWJ1ds5eaHX9MPoUSk0+g0yW7gmqnD2VJTz38/+xbDehfytx88IeqSRCQG1IPvJm48fzQzxvXne4+t1DzyItIpFPDdRCJh/N9PTmRk32K++NvFrNU88iJynBTw3UhhblYwjzx87leV7K7XFMMicuwU8N3MkN4F3HrlKazZtod//v0SWnRmjYgcIwV8NzR1RB++ceEYnlixlZ88/UbU5YhImtJZNN3UNWcOY8WmGn7y9BuMGVDMjPEDoi5JRNKMevDdlJnxnUvGM3lIKf9836us3lIbdUkikmYU8N1YblaS2646lYKcJF+5/1X90lVEOkQB3831LcnjXy4ax9INu7j7xbVRlyMiaaRdAW9mc8ysxFLuNLNFZjY97OIk5aIJA/jQqDJ+8MRqNu7cF3U5IpIm2tuD/6y71wDTgZ7A1cC/h1aVHMTM+M7HxuMON/9B89WISPu0N+AtuL8A+LW7L2+zTrrA4F4F/NNHRvLUyioef21L1OWISBpob8AvNLMnSAX8n82sGGg52gvMLM/MXjazV81suZn96/EWm+k+O3U4YweUcPPDy6mpa4y6HBHp5tob8NcBXwNOc/e9QDZw7fu8ph44190nApOAGWZ2+jFXKmQlE/z7x09m2+56/vPxVVGXIyLdXHsD/gxgtbvvNLOrgG8AR71itKfsDhazg5sGj4/ThEGlXHPmcO5Z8A4L122PuhwR6cbaG/A/B/aa2UTgBuAt4Ffv9yIzS5rZEqAKeNLdFxxzpbLfDdNHMbBHPjc9uIyGpqOOlIlIBmtvwDd56tSNWcAt7n4rUPx+L3L3ZnefBAwCppjZ+EO3MbPZZlZpZpXV1ZoHvT0Kc7P49qxxvL51N3e8sCbqckSkm2pvwNea2U2kTo/8o5klSA25tIu77wTmAzMO89xcd69w94qysrL27jLjTRvTj/PG9OO///KWvnAVkcNqb8BfTupL08+6+xZSPfL/OtoLzKzMzEqDx/nARwB9M9iJvnTeSGrqmvjl/66NuhQR6YbaFfBBqN8D9DCzmUCdu7/fGPwAYL6ZLQVeITUG/+hxVSsHGV/eg4+M7ccdz69RL15E3qO9UxV8EngZ+ATwSWCBmV12tNe4+1J3n+zuE9x9vLt/+/jLlUPNmZbqxd+tXryIHKK9QzT/h9Q58J9x908DU4BvhleWtNf48h6cN6Yvd7zwNrXqxYtIG+0N+IS7V7VZfrcDr5WQzZk2il37GjXbpIgcpL0h/biZ/dnMrjGza4A/Ao+FV5Z0xMmDejDtJPXiReRg7f2S9SvAXGBCcJvr7l8NszDpmDnnjWTn3kZ+9dd1UZciIt1Eu6/J6u4PAA+EWIschwmDSjn3pL7c/vwaPnPmMIpydbldkUx31B68mdWaWc1hbrVmVtNVRUr7zJnW2otfG3UpItINHDXg3b3Y3UsOcyt295KuKlLaZ+LgUs4ZXcbtz61hT31T1OWISMR0JkzMzJk2kh0aixcRFPCxM3lITz40qow7nl9DfVNz1OWISIQU8DH02bOG8+6eBl3aTyTDKeBj6IMj+jC0dwG/eUnDNCKZTAEfQ4mEcdUHhvLK2h2s2qKTnUQylQI+pi47dRA5WQn14kUymAI+pnoW5nDRhIHMW7RR0xeIZCgFfIxdfcZQ9jQ089DijVGXIiIRUMDH2MRBPRhfXsKvX1pH6pK6IpJJFPAxZmZcffpQXt+6m1fW7oi6HBHpYgr4mLt4YjnFeVn8Wl+2imQcBXzM5eckuezUQTz+2maqa+ujLkdEupACPgNcdfpQGpud+yrXR12KiHQhBXwGOLGsiKkjenPPS+tobtGXrSKZQgGfIa4+fSibdtXxzKqq999YRGJBAZ8hzhvTj34lufqyVSSDKOAzRFYywRWnDeG516tZv31v1OWISBdQwGeQy04dBMDDr26KuBIR6QoK+AwyuFcBpw7tyR+WbNQvW0UyQGgBb2aDzWy+ma0ws+VmNiestqT9PjZpIK9v3c3KzbVRlyIiIQuzB98E3ODuY4HTgS+Y2dgQ25N2uHDCQLISxh+WaAIykbgLLeDdfbO7Lwoe1wIrgfKw2pP26VWYw9mjynj41U206Jx4kVjrkjF4MxsGTAYWHOa52WZWaWaV1dXVXVFOxps1aSCbd9Wx4O3tUZciIiEKPeDNrAh4APiSu7/n+nHuPtfdK9y9oqysLOxyBPjI2H4U5CQ1TCMSc6EGvJllkwr3e9z9wTDbkvYryMni/HH9eWzZZuqbmqMuR0RCEuZZNAbcCax09x+G1Y4cm1mTBlJT18T8VRoWE4mrMHvwU4GrgXPNbElwuyDE9qQDzhrRhz5FORqmEYmxrLB27O4vABbW/uX4ZCUTzJwwkN++/A41dY2U5GVHXZKIdDL9kjWDzZo0kIamFh5ftiXqUkQkBAr4DDZpcClDexfwkIZpRGJJAZ/BzIxZEwfy1zXvsmVXXdTliEgnU8BnuFmTy3GHRzTDpEjsKOAz3IllRZxc3kPDNCIxpIAXZk0ayPJNNbxZpRkmReJEAS9cPGkgCYN5i9WLF4kTBbzQtziPs0aW8dBizTApEicKeAHg0snlbNy5j5fXaoZJkbhQwAsA08elZph8SMM0IrGhgBcgNcPkjPH9+eOyzdQ1aoZJkThQwMt+l0wup7auiadXVkVdioh0AgW87HfmiX3oV5LLvMUboi5FRDqBAl72SyaMWZPK+cvqat7dXR91OSJynBTwcpBLJpfT1OI8unRz1KWIyHFSwMtBxgwo4aT+xTyos2lE0p4CXt7j0lPKeXX9Tt6q3h11KSJyHBTw8h6zJpWTMPiDevEiaU0BL+/RrySPqSP6MG/JRtw1dYFIulLAy2FdMrmc9dv3UbluR9SliMgxUsDLYZ0/rj/52UkeXKRhGpF0pYCXwyrMDaYuWLpJUxeIpCkFvBzRJZPLqalr4plVmrpAJB0p4OWIpo7oQ3lpPne98La+bBVJQwp4OaJkwph99glUrtvBgrc1T7xIulHAy1Fdftpg+hTlcsszb0Zdioh0UGgBb2Z3mVmVmb0WVhsSvrzsJJ/74HBeeHMbi9/RKZMi6STMHvwvgRkh7l+6yKdOH0ppQTa3zlcvXiSdhBbw7v4coIHbGCjKzeLaM4fz1MoqVmyqibocEWmnyMfgzWy2mVWaWWV1dXXU5cgRXHPmMIpys7j1L+rFi6SLyAPe3ee6e4W7V5SVlUVdjhxBj4Jsrj5jKI8t26xZJkXSROQBL+njurOGk5uV4Od/eSvqUkSkHRTw0m59inL5mylDmLd4I+u37426HBF5H2GeJnkv8FdgtJltMLPrwmpLus7ss08gacZtz6kXL9LdhXkWzd+4+wB3z3b3Qe5+Z1htSdcZ0COfj586iPte2cDWmrqoyxGRo9AQjXTY33/oRJrd+X86L16kW1PAS4cN6V3AlVOG8KuX1vH8Gzq1VaS7UsDLMfn6BWMY2beIf/r9EqpqNVQj0h0p4OWY5OckueXKU9hd38QN971KS4umExbpbhTwcsxG9SvmWxeN4/k3tvHzZ3VWjUh3o4CX43L5aYO5aOJAfvjk61Su1dRDIt2JAl6Oi5nxvUvGU16az/X3Lmbn3oaoSxKRgAJejltxXja3XDmZ6t313Hj/Ul3eT6SbUMBLp5gwqJSvzjiJJ1Zs5e4X10ZdjoiggJdOdN1Zw5l2Ul++9cgKvvfYShqaWqIuSSSjKeCl05gZt1x5Cp/6wBDmPreGS3/+v6zR1MIikVHAS6fKz0ny3UtO5rarT2XDjn3M/NkL3Fe5XuPyIhFQwEsozh/Xn8fnnM3EQaXceP9SvnjvYnbta4y6LJGMooCX0PTvkcdv/vYD3DhjNH9+bQvn/+g5bnnmDTbt3Bd1aSIZwbrT/zpXVFR4ZWVl1GVICJas38n3H1vJgre3YwZnjejDJyoGM31sP/Kyk1GXJ5K2zGyhu1cc9jkFvHSld97dy/2LNvDAwg1s3LmPkrwsLpo4kA+NKuO0Yb3oWZgTdYkiaUUBL91OS4vz1zXv8j+V63l8+RbqGlOnVI7oW8Rpw3px2rCenDasF4N65mNmEVcr0n0p4KVbq2tsZtnGXbz89nYq126nct0OauuaACgtyGZUv2JG9ytmVP/gvl8RpQXq6YvA0QM+q6uLETlUXnYy6LX3AqC5xXl9ay2Va7ezckstr2+p5aElG/eHPkCvwhwG9MgLbvkMKM1jYI98+pXk0bMwm54FOZQWZJObpfF9yVwKeOl2kgljzIASxgwo2b/O3dlSU8fqLbWs3lLLuu172bxzHxt27OOVtTuOeApmYU6S0oKcNqGfQ8+CbErzs/evL8nLpjgvm+K8LEryU/dFOVkkEhoakvSmgJe0YGapnnqPfM4Z3fc9z++pb2LzrjqqaurYsbeRHXsb2Lm3IfV4TwM7gsfrt+9lx95GauoaOdropBnkZycpyEmSl50kPztJfvC4ICdJYW4WhfvvsyjMzaIgJ0l2MkFW0sgJ7rOTCbKTRm5WktysROo+O0FuVoKcrAQ5yeA+eKzvG6QzKeAlFgpzsxjRt4gRfYvatX1zi7NrX+qDoLauiZp9jdTWNVFbd+B+b0Mz+xpTt7rGZvYFy9v3NLB++1721Dezp76JPQ1NdNYFrVoDPztpJBMJshJGVtLIShjJROoDIycrtT57/7ap7bMSCZKJA9tmJYP71vX795PYv40ZJMxIBPfW5nHCIJEwEmYkLbVtMnhdwg6+TyZSH8JJS61LJGizDYfZPrXeWrcPtoHUh2ur1g88C9YbqW3ZX+OB/bRtq23bmfyhqYCXjJRMGL0Kc+jVCadlujt1jS3sbWiisdlpbG6hqSV139jcQkNTcGtuob6xhfqmFuqbmqlrbPN8c2p963JTcwuNLU5zs9PU4jS1BPtsOrDvhqYW9tQfaLO55cC2B17nNLV5rvU+kySCD6a2HzKQ+tDYL1hwhxb3A/cAzoEPN7PgQy+1DBZ88Bz4ADqwfOAD63DPWdCuAb0Lc7nv787o9GNXwIscJzMjPyc1hJMO3FNB33JImLW409ICTuq55hZPbevBtsEHRLN76nHrflpSr2/2YPtguXWbw722pU2bB9pP3R8o9MDD1rB1P1AfQftOa60H6ki1x0G1ttbQup8DzXjwd0mFtpH6P5e2Id36N2sO6m37GFL3rbWl7g8ss3+57TEcWMahJD+cKFbAi2QYs9RwjcRfqHPRmNkMM1ttZm+a2dfCbEtERA4WWsCbWRK4FfgoMBb4GzMbG1Z7IiJysDB78FOAN919jbs3AL8DZoXYnoiItBFmwJcD69ssbwjWHcTMZptZpZlVVldXh1iOiEhmiXw+eHef6+4V7l5RVlYWdTkiIrERZsBvBAa3WR4UrBMRkS4QZsC/Aow0s+FmlgNcATwcYnsiItJGaOfBu3uTmX0R+DOQBO5y9+VhtSciIgfrVvPBm1k1sO4YX94H2NaJ5aQLHXdm0XFnlvYc91B3P+wXmN0q4I+HmVUeadL7ONNxZxYdd2Y53uOO/CwaEREJhwJeRCSm4hTwc6MuICI67syi484sx3XcsRmDFxGRg8WpBy8iIm0o4EVEYirtAz6T5pw3s7vMrMrMXmuzrpeZPWlmbwT3PaOssbOZ2WAzm29mK8xsuZnNCdbH+rgBzCzPzF42s1eDY//XYP1wM1sQvOd/H/xSPFbMLGlmi83s0WA59scMYGZrzWyZmS0xs8pg3TG/19M64DNwzvlfAjMOWfc14Gl3Hwk8HSzHSRNwg7uPBU4HvhD8N477cQPUA+e6+0RgEjDDzE4H/gP4kbuPAHYA10VYY1jmACvbLGfCMbf6sLtPanP++zG/19M64MmwOefd/Tlg+yGrZwF3B4/vBj7WpUWFzN03u/ui4HEtqX/05cT8uAE8ZXewmB3cHDgXuD9YH7tjN7NBwIXAHcGyEfNjfh/H/F5P94Bv15zzMdfP3TcHj7cA/aIsJkxmNgyYDCwgQ447GKpYAlQBTwJvATvdvSnYJI7v+R8DNwItwXJv4n/MrRx4wswWmtnsYN0xv9d10e0YcXc3s1ie92pmRcADwJfcvab1avcQ7+N292ZgkpmVAvOAkyIuKVRmNhOocveFZnZO1PVE4Cx332hmfYEnzWxV2yc7+l5P9x685pyHrWY2ACC4r4q4nk5nZtmkwv0ed38wWB37427L3XcC84EzgFIza+2cxe09PxW42MzWkhpyPRf4CfE+5v3cfWNwX0XqA30Kx/FeT/eA15zzqeP9TPD4M8AfIqyl0wXjr3cCK939h22eivVxA5hZWdBzx8zygY+Q+g5iPnBZsFmsjt3db3L3Qe4+jNS/52fc/VPE+JhbmVmhmRW3PgamA69xHO/1tP8lq5ldQGrMrnXO+e9GXFJozOxe4BxSU4huBW4GHgLuA4aQmmr5k+5+6BexacvMzgKeB5ZxYEz266TG4WN73ABmNoHUl2pJUp2x+9z922Z2AqnebS9gMXCVu9dHV2k4giGaL7v7zEw45uAY5wWLWcBv3f27ZtabY3yvp33Ai4jI4aX7EI2IiByBAl5EJKYU8CIiMaWAFxGJKQW8iEhMKeBFOoGZndM68wypT+0AAAGeSURBVKFId6GAFxGJKQW8ZBQzuyqYY32Jmd0WTOa128x+FMy5/rSZlQXbTjKzl8xsqZnNa52H28xGmNlTwTzti8zsxGD3RWZ2v5mtMrN7rO2EOSIRUMBLxjCzMcDlwFR3nwQ0A58CCoFKdx8HPEvqF8IAvwK+6u4TSP2StnX9PcCtwTztZwKtM/1NBr5E6toEJ5CaV0UkMppNUjLJNOBU4JWgc51PauKmFuD3wTa/AR40sx5Aqbs/G6y/G/ifYK6QcnefB+DudQDB/l529w3B8hJgGPBC+IclcngKeMkkBtzt7jcdtNLsm4dsd6zzd7SdG6UZ/fuSiGmIRjLJ08BlwVzbrde6HErq30HrTIVXAi+4+y5gh5l9MFh/NfBscFWpDWb2sWAfuWZW0KVHIdJO6mFIxnD3FWb2DVJXzEkAjcAXgD3AlOC5KlLj9JCamvW/gwBfA1wbrL8auM3Mvh3s4xNdeBgi7abZJCXjmdludy+Kug6RzqYhGhGRmFIPXkQkptSDFxGJKQW8iEhMKeBFRGJKAS8iElMKeBGRmPr/MJqZIClaYPYAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3elbMNg4z4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a2950ae-80a4-433b-c4ce-b5c8adb67e5f"
      },
      "source": [
        "after_train_predictions = model(input_example)\n",
        "after_sampled_indices = tf.argmax(after_train_predictions[0],1)\n",
        "\n",
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入進訓練後的model後獲得：\")\n",
        "print()\n",
        "\n",
        "[print(index_2_word[ind],end=\"\") for ind in after_sampled_indices.numpy()]\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原本的中文字序列：\n",
            "你的父？\n",
            "薇奧拉 我是薩人。西巴斯辛是我\n",
            "----------------------------------------\n",
            "輸入進訓練後的model後獲得：\n",
            "\n",
            "的誓？\n",
            "薇奧拉 我是薩人。西巴斯辛是我的\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-ZgfcpVUpbc"
      },
      "source": [
        "## 7. 做預測\n",
        "\n",
        "![](https://i.imgur.com/YsOj6Mw.png)\n",
        "\n",
        "在實際生成文字時，我們會想要增加一些隨機性。比如”天天出去” 不加入隨機 “天天天天” 如果我們全部輸出的字都是取softmax最大可能性，則一個訓練完美的model會把整本書給輸出出來。但是我們要的是，希望電腦在最大可能性的幾個字中隨機挑選一個字出來。\n",
        "\n",
        "tf.random.categorical 會根據softmax機率後隨機挑選字，但是我們不希望因為模型很爛導致不合理的字被選中，因此我們會除上一個temperature來增加可能字的比重。\n",
        "\n",
        "EX: \"天天出去\" 預測下一個字\n",
        "1. 玩 : 0.3 \n",
        "2. 天 : 0.1 \n",
        "3. 浪 : 0.4 \n",
        "\n",
        "\"天\"有的機率被印出，我們不希望。所以我們可以在每一個機率除上一個temperature(0.01)\n",
        "1. 玩 : 30 \n",
        "2. 天 : 10 \n",
        "3. 浪 : 40 \n",
        "原本\"浪\"跟\"天\"差0.3，除temperature後差30\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3ryhOIg4-qB"
      },
      "source": [
        "# 預測文字，並把預測文字循環當作下一次的輸入\n",
        "\n",
        "# 設定你的temperature\n",
        "temperature = 0.01\n",
        "\n",
        "def generateWords(input,words=500):\n",
        "  [print(index_2_word[ind],end=\"\") for ind in input]\n",
        "  for i in range(words):\n",
        "    next_input = tf.expand_dims(input,axis=0)\n",
        "    predicts = model(next_input)\n",
        "    predicts = predicts[:,-1,:]\n",
        "    predicts /= temperature\n",
        "    result = tf.random.categorical(\n",
        "        predicts,num_samples=1\n",
        "    )\n",
        "    chinese_ind = tf.squeeze(result).numpy()\n",
        "    print(index_2_word[chinese_ind],end=\"\")\n",
        "    input = input+[chinese_ind]\n",
        "    input = input[-seq_len:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7ELuAjW3rKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "190df3f3-0bad-4a50-b787-a34370ba2e0e"
      },
      "source": [
        "init_seq = \"第十二夜\"\n",
        "init_seq_ind = [word_2_index[w] for w in init_seq]\n",
        "input = init_seq_ind[-seq_len:]\n",
        "\n",
        "generateWords(input,800)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "第十二夜等我；我希望您不會見他來。\n",
            "托比 我們會把你間作的人，請他留吧。\n",
            "薇奧拉 我要來，殿下，朋友；我是個。\n",
            "托比 我的侄女見什麼鬼把她哥哥的死死。\n",
            "小丑 你們不過起這樣的嗎？\n",
            "薇奧拉 您僕人的名字是西薩里奧，美貌的人，\n",
            "小丑 是的，\n",
            "什麼您要是我的。\n",
            "薇奧拉 不，我的名字不，我要為你的。\n",
            "奧麗維亞 把你的尊意告訴你！\n",
            "薇奧拉 我不是個要錢的信差，差生，我可以一直做的最的，我可以用的希望來您的；我可以跟他們兩人連無條的地。可是您，先生，卻是您的僕人，您是什麼意思？\n",
            "奧麗維亞 我的意思，他的嗎？\n",
            "薇奧拉 不，殿下，我要叫您說話。\n",
            "費邊 他在這兒給他的婚了！\n",
            "小丑 唉，我的心不是是的傻子。\n",
            "馬伏里奧 你怎麼說，小姐？\n",
            "馬伏里奧 我們都叫他去吧，我們要聽一個瘋；我是個瘋子也會傷歡你，為來的眼。\n",
            "薇奧拉 唉！我好好，這樣正是我的靈魂。\n",
            "馬伏里奧 我知道你在說些什麼，很得我的；不是我的僕人，得得這樣的話，然是您不過我的大人。\n",
            "奧麗維亞 唉！\n",
            "他要是你的話？\n",
            "薇奧拉 我的來意，小姐，我是個瘋子。\n",
            "托比 小姐，我來了他；他是個魔鬼，我是個瘋子。\n",
            "馬伏里奧 （在）托巴斯師傅！\n",
            "小丑 嘿，我可真是多才多呢；雖然我們兩四力的話，可是我卻不肯服，因此，要是我在這兒給到了，可是我的話怎麼清，我的事情怎樣？\n",
            "薇奧拉 我的來意，小姐，我是個瘋子。\n",
            "托比 小姐，我來不過是個傻子；我知道我的錢不夠，\n",
            "小丑 不，你們把我的名兄。\n",
            "小丑 您說，先生，我是個瘋子。\n",
            "馬伏里奧 「我的命在，，，請你的著你的臉人的話。\n",
            "薇奧拉 我可以還給你。\n",
            "奧麗維亞 我不要叫他蛋出；他不是我的一樣，不要叫您是什麼意？\n",
            "奧麗維亞 他是什麼話？\n",
            "馬伏里奧 「有有的人是來的富貴，」……\n",
            "奧麗維亞 你的黃襪子！\n",
            "馬伏里奧 「我的命在，，，，我的前不過去，我的愛情是個世的的。\n",
            "安德魯 我們得什麼絕妙的理由，可是我有不能跟我。\n",
            "薇奧拉 我是一個使者"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdT8wg_P6CtF"
      },
      "source": [
        "# 不要執行這一個block\n",
        "# import time\n",
        "# while True:\n",
        "#   time.sleep(5)\n",
        "#   pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-_4vCX4e3ZA"
      },
      "source": [
        "## 作業2.1 (30%)\n",
        "\n",
        "使用[爬蟲程式](https://colab.research.google.com/drive/1f_HvQEvgkJPFc473TlA-I_3EmkThA2SR?usp=sharing)來取得一個新的文本資料集，或是不管你從哪裡取得的資料集也可以(不要再張愛玲了，不限中英文)。然後丟入這個模型來看看AI生成文字的成果，將**結果**與**你的心得**(不是機器產生的心得)，貼上pdf。\n",
        "\n",
        "請隨意修改本colab的模型與參數來達到更好的結果。\n",
        "\n",
        "資料集越有趣越好，比如你可以去爬PTT文章來製作廢文產生器。去爬Dcard製作幻想文產生器。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erwsMKL08Ql9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}